{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'>Python_Programming_TensorFlow_Keras</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'>Question 1:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use the make moons dataset to sequentially build three different SVM classifiers. Each subsequent SVM classifier should be designed to “improve” the previous SVM classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Using comments after each classifier justify the choice for the next SVM classifier that you are building (the justification should be prior to building the classifier). The results do not have to show that subsequent SVM classifiers were better, but the justification provided for trying the ‘next’ classifier each time should make sense.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feel free to use any choice of noise, or number of points, but all comparisons should be on a test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Finally build any ensemble model as well, and compare the predictions of the ensemble to the three SVM classifiers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM Classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate Make Moons data and plot the datapoints\n",
    "X, y = make_moons(n_samples=400, noise=0.25, random_state=42)\n",
    "\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 2), (80, 2), (320,), (80,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train test split  (80-20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASSIFIER - #1: We'll start with a Linear Classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        33\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.89        80\n",
      "   macro avg       0.88      0.90      0.89        80\n",
      "weighted avg       0.90      0.89      0.89        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#Import libraries and build 1st Classifier model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly1_kernel_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", LinearSVC(C=100, loss=\"hinge\", random_state=42))\n",
    "    ])\n",
    "poly1_kernel_svm_clf.fit(X_train, y_train)\n",
    "y1_pred=poly1_kernel_svm_clf.predict(X_test)\n",
    "classification_poly1 = classification_report(poly1_kernel_svm_clf.predict(X_test),y_test)\n",
    "print(classification_poly1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASSIFIER - #2: Our data follows Polynomial pattern so I used Polynomial Classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        36\n",
      "           1       0.95      0.91      0.93        44\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.92      0.93      0.92        80\n",
      "weighted avg       0.93      0.93      0.93        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build 2nd Classifier model\n",
    "poly2_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=10, coef0=10, C=100))\n",
    "    ])\n",
    "\n",
    "poly2_kernel_svm_clf.fit(X_train, y_train)\n",
    "y2_pred=poly2_kernel_svm_clf.predict(X_test)\n",
    "classification_poly2 = classification_report(poly2_kernel_svm_clf.predict(X_test),y_test)\n",
    "print(classification_poly2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASSIFIER - #3: Changed parameters for the Polynomial Classifier like degree and C value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHANGE - 1: Increasing degree changes the multidimensional space used to classify changes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHANGE - 2: Increasing C value adds up additional space between dimensions which helps to avoid misclassification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build 3rd Classifier model\n",
    "poly3_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=15, coef0=20, C=100))\n",
    "    ])\n",
    "poly3_kernel_svm_clf.fit(X_train, y_train)\n",
    "y3_pred=poly2_kernel_svm_clf.predict(X_test)\n",
    "classification_poly3 = classification_report(poly3_kernel_svm_clf.predict(X_test),y_test)\n",
    "print(classification_poly3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Build three ensemble models\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7625\n",
      "RandomForestClassifier 0.9375\n",
      "SVC 0.9\n",
      "VotingClassifier 0.8875\n"
     ]
    }
   ],
   "source": [
    "#Show ensemble model accuracies\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULT: SVM Classifier shows better accuracy than Ensemble Models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'>Question 2:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict “ocean proximity” in the housing.csv file using both MLP Classifier and Keras. Use 50% of the data as the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using the MLP Classifier, build and train a deep neural network with three hidden layers of 15, 10 and 7 nodes with max iterations set to 500. Do this with and without early stopping. In each case, compute and print the confusion matrix on the test set, as well as print the iteration at which the training terminated. Did early stopping help, or hurt?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Use Keras to build a network of the same structure (i.e. nodes and hidden layers). In Keras it is OK if the other hyper-parameters are different and in Keras you can build only one model (with OR without early stopping – your choice). Print the confusion matrix on the test set (with or without early stopping – up to you). Was the model built in keras better or worse than what you got previously with MLP classifiers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MLP Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas library\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "#Read 'Housing' csv file\n",
    "housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20433 entries, 0 to 20432\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20433 non-null  float64\n",
      " 1   latitude            20433 non-null  float64\n",
      " 2   housing_median_age  20433 non-null  float64\n",
      " 3   total_rooms         20433 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20433 non-null  float64\n",
      " 6   households          20433 non-null  float64\n",
      " 7   median_income       20433 non-null  float64\n",
      " 8   median_house_value  20433 non-null  float64\n",
      " 9   ocean_proximity     20433 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Drop the missing values\n",
    "housing.dropna(axis=0, inplace=True)\n",
    "\n",
    "#Index reset\n",
    "housing.reset_index(inplace=True, drop=True)\n",
    "\n",
    "housing.describe()\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN          9034\n",
       "INLAND             6496\n",
       "NEAR OCEAN         2628\n",
       "NEAR BAY           2270\n",
       "ISLAND                5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the response and target variables and drop other labels\n",
    "housing_X = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "#Select the label\n",
    "housing_target = housing[[\"ocean_proximity\"]]\n",
    "housing_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transform using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "housing_X_std = scaler.fit_transform(housing_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10216, 9), (10217, 9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train test split (50-50%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_X_std, housing_target, test_size=0.5)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(15, 10, 7), max_iter=500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build DNN model using MLP classifier without early stopping\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "dnn_clf = MLPClassifier(hidden_layer_sizes=(15,10,7),\n",
    "                       max_iter=500)\n",
    "\n",
    "dnn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DNN without early stopping:  0.9295292160125281\n"
     ]
    }
   ],
   "source": [
    "#Print accuracy for the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = dnn_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of DNN without early stopping: \", str(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4246,   62,    0,   20,  217],\n",
       "       [ 149, 3055,    0,   12,    1],\n",
       "       [   0,    0,    0,    0,    3],\n",
       "       [  17,    2,    0, 1069,   39],\n",
       "       [ 162,    0,    0,   36, 1127]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(15, 10, 7), max_iter=500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build DNN model using MLP classifier with early stopping\n",
    "dnn_clf_with_stop = MLPClassifier(hidden_layer_sizes=(15,10,7),\n",
    "                       max_iter=500,\n",
    "                       early_stopping=True)\n",
    "\n",
    "dnn_clf_with_stop.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DNN with early stopping:  0.8620925907800724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4022,   76,    0,  226,  221],\n",
       "       [ 146, 3018,    0,   53,    0],\n",
       "       [   0,    0,    0,    0,    3],\n",
       "       [ 135,   33,    0,  913,   46],\n",
       "       [ 348,    0,    0,  122,  855]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print accuracy and confusion matrix for the model\n",
    "y_test_pred_with_stop = dnn_clf_with_stop.predict(X_test)\n",
    "print(\"Accuracy of DNN with early stopping: \", str(accuracy_score(y_test, y_test_pred_with_stop)))\n",
    "confusion_matrix(y_test, y_test_pred_with_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_with_stop.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULT: Early Stopping hurts the model as we got less accuracy (Without: 93% vs With: 86%).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20433, 9), (20433, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target and response variables\n",
    "housing_X_std.shape,housing_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transform on the target variable\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_labels_ord = ordinal_encoder.fit_transform(housing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_labels_int = housing_labels_ord.astype(int)\n",
    "\n",
    "housing_labels_int.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10216, 9), (10217, 9), (10216, 1), (10217, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train test split (50-50%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_X_std, housing_labels_int, test_size=0.5)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "#Fix random seed reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model without early stopping\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15, input_dim=9, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "\n",
    "#Final layer: Need 5 nodes with softmax (As we have 5 categories)\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 0s 541us/step - loss: 1.3839 - accuracy: 0.4226\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 494us/step - loss: 1.1691 - accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 542us/step - loss: 1.0048 - accuracy: 0.6182\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 600us/step - loss: 0.8366 - accuracy: 0.6913\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 978us/step - loss: 0.6905 - accuracy: 0.7384\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 939us/step - loss: 0.6123 - accuracy: 0.7625\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.5678 - accuracy: 0.7748\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.5273 - accuracy: 0.7843\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 542us/step - loss: 0.4841 - accuracy: 0.7949\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.4367 - accuracy: 0.8176\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 639us/step - loss: 0.4051 - accuracy: 0.8316\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.3883 - accuracy: 0.8385\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.3820 - accuracy: 0.8395\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 600us/step - loss: 0.3705 - accuracy: 0.8451\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 552us/step - loss: 0.3658 - accuracy: 0.8506\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.3615 - accuracy: 0.8516\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.3558 - accuracy: 0.8536\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.3615 - accuracy: 0.8526\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.3517 - accuracy: 0.8601\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.3464 - accuracy: 0.8594\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 504us/step - loss: 0.3433 - accuracy: 0.8619\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.3459 - accuracy: 0.8616\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.3429 - accuracy: 0.8593\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 571us/step - loss: 0.3385 - accuracy: 0.8656\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 552us/step - loss: 0.3362 - accuracy: 0.8649\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 571us/step - loss: 0.3253 - accuracy: 0.8679\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 562us/step - loss: 0.3273 - accuracy: 0.8692\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.3233 - accuracy: 0.8689\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 562us/step - loss: 0.3107 - accuracy: 0.8714\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 533us/step - loss: 0.3089 - accuracy: 0.8716\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 508us/step - loss: 0.3111 - accuracy: 0.8720\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.3001 - accuracy: 0.8764\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 523us/step - loss: 0.2998 - accuracy: 0.8748\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 552us/step - loss: 0.2995 - accuracy: 0.8776\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.3011 - accuracy: 0.8785\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.2859 - accuracy: 0.8795\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 562us/step - loss: 0.2854 - accuracy: 0.8823\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.2815 - accuracy: 0.8902\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.2759 - accuracy: 0.8871\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2747 - accuracy: 0.8866\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 522us/step - loss: 0.2716 - accuracy: 0.8901\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2734 - accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2603 - accuracy: 0.8957\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 504us/step - loss: 0.2601 - accuracy: 0.8965\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.2611 - accuracy: 0.8923\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 503us/step - loss: 0.2585 - accuracy: 0.8940\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2595 - accuracy: 0.8914\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 542us/step - loss: 0.2579 - accuracy: 0.8953\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 542us/step - loss: 0.2503 - accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 562us/step - loss: 0.2512 - accuracy: 0.8994\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.2422 - accuracy: 0.8987\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2510 - accuracy: 0.8976\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.2457 - accuracy: 0.8984\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.2447 - accuracy: 0.8971\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2385 - accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 436us/step - loss: 0.2416 - accuracy: 0.9018\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2369 - accuracy: 0.9054\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2359 - accuracy: 0.9054\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2298 - accuracy: 0.9057\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 436us/step - loss: 0.2286 - accuracy: 0.9059\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2307 - accuracy: 0.9060\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2257 - accuracy: 0.9062\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2278 - accuracy: 0.9052\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2229 - accuracy: 0.9081\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2318 - accuracy: 0.9065\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2231 - accuracy: 0.9066\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2204 - accuracy: 0.9082\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.2218 - accuracy: 0.9102\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 600us/step - loss: 0.2193 - accuracy: 0.9089\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.2196 - accuracy: 0.9066\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 620us/step - loss: 0.2169 - accuracy: 0.9112\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 482us/step - loss: 0.2204 - accuracy: 0.9082\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.2144 - accuracy: 0.9110\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2085 - accuracy: 0.9104\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2085 - accuracy: 0.9123\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2095 - accuracy: 0.9126\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2046 - accuracy: 0.9152\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2097 - accuracy: 0.9123\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.2060 - accuracy: 0.9149\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.2097 - accuracy: 0.9125\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 504us/step - loss: 0.2006 - accuracy: 0.9143\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.2123 - accuracy: 0.9080\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 649us/step - loss: 0.1969 - accuracy: 0.9192\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 639us/step - loss: 0.2053 - accuracy: 0.9145\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 571us/step - loss: 0.2065 - accuracy: 0.9183\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 658us/step - loss: 0.1963 - accuracy: 0.9165\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 804us/step - loss: 0.2033 - accuracy: 0.9146\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 519us/step - loss: 0.2022 - accuracy: 0.9173\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.1984 - accuracy: 0.9166\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.1993 - accuracy: 0.9182\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2033 - accuracy: 0.9151\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.1970 - accuracy: 0.9172\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.1950 - accuracy: 0.9185\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.1890 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 0s 436us/step - loss: 0.1998 - accuracy: 0.9162\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.2017 - accuracy: 0.9142\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.1967 - accuracy: 0.9188\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.2047 - accuracy: 0.9115\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.1933 - accuracy: 0.9168\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.1952 - accuracy: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135585916d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.05)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4421,   43,    0,   26,   77],\n",
       "       [ 196, 3063,    0,   11,    0],\n",
       "       [   0,    0,    0,    0,    4],\n",
       "       [ 189,   46,    0,  875,    4],\n",
       "       [ 340,    0,    0,   67,  855]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "y_test_pred.shape,y_test.shape,X_test.shape\n",
    "\n",
    "#Test split prediction\n",
    "confusion_matrix(y_test,np.argmax(y_test_pred,axis=1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 415us/step - loss: 0.2564 - accuracy: 0.9018\n",
      "Accuracy on DNN without using early stopping:\n",
      "\n",
      "accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy on DNN without using early stopping:\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9207 - val_loss: 0.3491 - val_accuracy: 0.8503\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9198 - val_loss: 0.7449 - val_accuracy: 0.7514\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9146 - val_loss: 0.4144 - val_accuracy: 0.8812\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9191 - val_loss: 0.1963 - val_accuracy: 0.9183\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9189 - val_loss: 0.2577 - val_accuracy: 0.9014\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.9168 - val_loss: 0.2017 - val_accuracy: 0.9194\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9169 - val_loss: 0.4577 - val_accuracy: 0.8677\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9240 - val_loss: 0.2316 - val_accuracy: 0.8962\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9199 - val_loss: 0.2721 - val_accuracy: 0.8965\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13559bf5af0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model with early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=100, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 414us/step - loss: 0.2721 - accuracy: 0.8965\n",
      "Accuracy on DNN with using early stopping:\n",
      "\n",
      "accuracy: 89.65%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on test set\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy on DNN with using early stopping:\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the results,**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE - 1: Without Early Stopping -> MLP Classifier (93%) is better than model build in Keras (90%).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE - 2: With Early Stopping -> Model built in Keras (89%) is better than MLP Classifier (86%).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
